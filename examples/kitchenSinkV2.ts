// ---------------------------------------------------------------------------
// Flowneer â€” Kitchenâ€‘Sink v2: AI News Desk Multi-Agent Briefing System
// ---------------------------------------------------------------------------
// Builds on kitchenSink.ts and showcases every plugin added since v0.4:
//
//   memory     â†’ BufferWindowMemory tracks conversation context
//   tools      â†’ ToolRegistry with search / calculate / wiki tools
//   ReAct      â†’ withReActLoop (think â†’ tool-call â†’ observation â†’ repeat)
//   humanNode  â†’ ergonomic human-in-the-loop gate via .humanNode()
//   supervisor â†’ supervisorCrew runs intro/body/conclusion drafters in parallel
//   structured â†’ withStructuredOutput validates final synthesis via Zod-like schema
//   callbacks  â†’ withCallbacks fires LangChain-style lifecycle hooks
//   telemetry  â†’ withTelemetry emits OTEL-style spans via consoleExporter
//   versioned  â†’ withVersionedCheckpoint keeps git-like diff snapshots
//   parsers    â†’ parseJsonOutput Â· parseListOutput Â· parseRegexOutput on sections
//   eval       â†’ runEvalSuite scores final report quality
//   graph      â†’ withGraph declares inner DAG then .compile()s it
//
// Everything from v1 is retained:
//   withTiming Â· withHistory Â· withInterrupts Â· withCircuitBreaker Â· withTimeout
//   withCycles Â· withStepLimit Â· withAtomicUpdates Â· withAuditLog
//   withTokenBudget Â· withCostTracker Â· withRateLimit
//   withChannels Â· withStream Â· withFallback
//
// Run with: bun run examples/kitchenSinkV2.ts
// Requires: OPENAI_API_KEY environment variable
// ---------------------------------------------------------------------------

import { FlowBuilder, FlowError, InterruptError } from "../Flowneer";

// â”€â”€ Plugin imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Observability (v1 + new withCallbacks)
import {
  withTiming,
  withHistory,
  withInterrupts,
  withCallbacks,
} from "../plugins/observability";
import type { CallbackHandlers } from "../plugins/observability/withCallbacks";

// Resilience (same as v1)
import {
  withFallback,
  withCircuitBreaker,
  withTimeout,
  withCycles,
} from "../plugins/resilience";
import type { CircuitBreakerOptions } from "../plugins/resilience";

// Persistence (NEW: withVersionedCheckpoint replaces flat withCheckpoint)
import { withAuditLog, withVersionedCheckpoint } from "../plugins/persistence";
import type {
  AuditEntry,
  AuditLogStore,
  VersionedCheckpointEntry,
  VersionedCheckpointStore,
} from "../plugins/persistence";

// LLM (NEW: withStructuredOutput)
import {
  withTokenBudget,
  withCostTracker,
  withRateLimit,
  withStructuredOutput,
} from "../plugins/llm";

// Dev
import { withStepLimit, withAtomicUpdates } from "../plugins/dev";

// Messaging (same as v1)
import {
  withChannels,
  sendTo,
  receiveFrom,
} from "../plugins/messaging/withChannels";
import { withStream, emit } from "../plugins/messaging/withStream";

// NEW: Tools
import { withTools } from "../plugins/tools";
import type { Tool, ToolCall, ToolResult } from "../plugins/tools";

// NEW: Agent
import { withReActLoop, withHumanNode, resumeFlow } from "../plugins/agent";
import type { ThinkResult } from "../plugins/agent";

// NEW: Memory
import { withMemory, BufferWindowMemory, KVMemory } from "../plugins/memory";
import type { Memory } from "../plugins/memory";

// NEW: Output parsers
import {
  parseJsonOutput,
  parseListOutput,
  parseRegexOutput,
} from "../plugins/output";

// NEW: Telemetry
import {
  withTelemetry,
  TelemetryDaemon,
  consoleExporter,
} from "../plugins/telemetry";

// NEW: Graph
import { withGraph } from "../plugins/graph";

// NEW: Eval
import {
  runEvalSuite,
  containsMatch,
  f1Score,
  answerRelevance,
} from "../plugins/eval";
import type { EvalResult } from "../plugins/eval";

import { callLlm, callLlmWithUsage } from "../utils/callLlm";

// â”€â”€ Register all plugins (once per process) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Observability
FlowBuilder.use(withTiming);
FlowBuilder.use(withHistory);
FlowBuilder.use(withInterrupts);
FlowBuilder.use(withCallbacks); // NEW â€” label-aware lifecycle callbacks

// Resilience
FlowBuilder.use(withCircuitBreaker);
FlowBuilder.use(withTimeout);
FlowBuilder.use(withCycles);
FlowBuilder.use(withStepLimit);
FlowBuilder.use(withAtomicUpdates);

// Persistence
FlowBuilder.use(withVersionedCheckpoint); // NEW â€” diff-based versioned checkpoints
FlowBuilder.use(withAuditLog);

// LLM
FlowBuilder.use(withTokenBudget);
FlowBuilder.use(withCostTracker);
FlowBuilder.use(withRateLimit);
FlowBuilder.use(withStructuredOutput); // NEW â€” Zod-compatible output validator

// Messaging
FlowBuilder.use(withChannels);
FlowBuilder.use(withStream);

// Agent + Tools + Memory
FlowBuilder.use(withTools); // NEW â€” ToolRegistry attached to shared.__tools
FlowBuilder.use(withReActLoop); // NEW â€” think â†’ tool-call â†’ observe loop
FlowBuilder.use(withHumanNode); // NEW â€” ergonomic interrupt / resume
FlowBuilder.use(withMemory); // NEW â€” Memory attached to shared.__memory

// Telemetry
FlowBuilder.use(withTelemetry); // NEW â€” OTEL-style spans

// Graph
FlowBuilder.use(withGraph); // NEW â€” DAG composition

// Fallback (last â†’ innermost wrapStep)
FlowBuilder.use(withFallback);

// â”€â”€ Pricing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const PRICE_IN = 1.1 / 1_000_000;
const PRICE_OUT = 4.4 / 1_000_000;
const calcCost = (inp: number, out: number) => inp * PRICE_IN + out * PRICE_OUT;

// â”€â”€ Shared state type â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface BriefingState {
  topic: string;
  // Research phase
  facts: string[];
  // Sections
  intro?: string;
  body?: string;
  conclusion?: string;
  // Structured synthesis
  briefing?: { title: string; summary: string; keyPoints: string[] };
  // Evaluation
  evalResults?: EvalResult<BriefingState>[];
  // Token tracking
  tokensUsed: number;
  // Fallback
  lastError?: string;
  // Agent internals
  __reactExhausted?: boolean;
  __toolResults?: ToolResult[];
  __humanPrompt?: string;
  __humanFeedback?: string;
  // Memory
  __memory?: Memory;
  // Structured output
  __llmOutput?: string;
  __structuredOutput?: unknown;
  __validationError?: string;
  // Plugin internals (v1 convention)
  __stepCost?: number;
  __cost?: number;
  __batchItem?: string;
  __history?: any[];
  __timings?: Record<number, number>;
  __channels?: Map<string, unknown[]>;
  __stream?: (chunk: unknown) => void;
  __fallbackError?: {
    stepIndex: number;
    stepType: string;
    message: string;
    stack?: string;
  };
}

// â”€â”€ Tool definitions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// These are mock implementations â€” swap for real APIs in production.

const searchTool: Tool = {
  name: "search",
  description: "Search the web for recent information on a topic.",
  params: {
    query: {
      type: "string",
      description: "Search query string",
      required: true,
    },
  },
  async execute({ query }: { query: string }) {
    // Mock â€” real impl would call SerpAPI, Tavily, etc.
    return `[mock search results for "${query}"]: Found 3 recent articles discussing key developments.`;
  },
};

const calculatorTool: Tool = {
  name: "calculate",
  description: "Evaluate a simple mathematical expression.",
  params: {
    expression: {
      type: "string",
      description: "Math expression, e.g. '2 + 2'",
      required: true,
    },
  },
  execute({ expression }: { expression: string }) {
    try {
      // eslint-disable-next-line no-new-func
      return String(new Function(`return ${expression}`)());
    } catch {
      return "Error: could not evaluate expression";
    }
  },
};

const wikiFetchTool: Tool = {
  name: "wiki_summary",
  description: "Fetch a one-paragraph Wikipedia summary for a term.",
  params: {
    term: {
      type: "string",
      description: "Term or concept to look up",
      required: true,
    },
  },
  async execute({ term }: { term: string }) {
    return `[mock wiki summary for "${term}"]: A widely-used concept with several important dimensions.`;
  },
};

// â”€â”€ Memory setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const conversationMemory = new BufferWindowMemory({ maxMessages: 20 });
// KVMemory for persisting named facts between steps
const kvMemory = new KVMemory();

// â”€â”€ Versioned checkpoint store â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Stores diff-based versioned checkpoints (like git commits).

const versionedStore: VersionedCheckpointStore<BriefingState> = (() => {
  const entries = new Map<string, VersionedCheckpointEntry<BriefingState>>();
  let snapshots = new Map<string, BriefingState>();
  let counter = 0;

  return {
    save(entry) {
      const id = `v${++counter}`;
      // Upgrade the entry object in place with the resolved id
      (entry as any).resolvedId = id;
      entries.set(id, entry);
      console.log(
        `  ğŸ’¾  [versioned checkpoint v${counter}] step ${entry.stepIndex}, diff keys: ${Object.keys(entry.diff).join(", ") || "(none)"}`,
      );
    },
    resolve(version) {
      // withVersionedCheckpoint rebuilds state from diffs internally.
      // This resolve is called by resumeFrom() â€” safe to throw for demo.
      throw new Error(`resolve("${version}") not implemented in mock store`);
    },
  };
})();

// â”€â”€ Audit log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const auditLog: AuditEntry<BriefingState>[] = [];
const auditStore: AuditLogStore<BriefingState> = {
  append(entry) {
    auditLog.push(entry);
  },
};

// â”€â”€ Telemetry daemon â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// A single daemon is shared across the whole process. consoleExporter logs
// spans to stdout; swap for otlpExporter to push to a collector endpoint.

const telemetryDaemon = new TelemetryDaemon({
  exporter: consoleExporter,
  flushIntervalMs: 10_000, // flush every 10 s
  maxBuffer: 50,
});

// â”€â”€ Callback handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Label any step "llm:*", "tool:*", or "agent:*" to fire the matching handler.

const callbacks: CallbackHandlers<BriefingState> = {
  onLLMStart: (meta) =>
    console.log(`  ğŸ¤–  [llm:start]  step ${meta.index} "${meta.label ?? ""}"`),
  onLLMEnd: (meta) =>
    console.log(`  ğŸ¤–  [llm:end]    step ${meta.index} "${meta.label ?? ""}"`),
  onToolStart: (meta) =>
    console.log(`  ğŸ”§  [tool:start] step ${meta.index} "${meta.label ?? ""}"`),
  onToolEnd: (meta) =>
    console.log(`  ğŸ”§  [tool:end]   step ${meta.index} "${meta.label ?? ""}"`),
  onAgentAction: (meta) =>
    console.log(`  ğŸ§   [agent:act]  step ${meta.index} "${meta.label ?? ""}"`),
  onAgentFinish: (meta) =>
    console.log(`  ğŸ§   [agent:done] step ${meta.index} "${meta.label ?? ""}"`),
  onChainStart: (meta) => console.log(`  â›“   [chain:start] step ${meta.index}`),
  onChainEnd: (meta) => console.log(`  â›“   [chain:end]   step ${meta.index}`),
  onError: (meta, err) =>
    console.error(
      `  âŒ  [callback:err] step ${meta.index}:`,
      (err as Error).message,
    ),
};

// â”€â”€ Structured output schema â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// A structurally Zod-compatible validator object (no Zod dependency needed).

const briefingSchema = {
  parse(value: unknown): {
    title: string;
    summary: string;
    keyPoints: string[];
  } {
    if (typeof value !== "object" || value === null)
      throw new Error("Expected an object");
    const v = value as Record<string, unknown>;
    if (typeof v.title !== "string") throw new Error("Missing title");
    if (typeof v.summary !== "string") throw new Error("Missing summary");
    if (!Array.isArray(v.keyPoints)) throw new Error("Missing keyPoints array");
    return {
      title: String(v.title),
      summary: String(v.summary),
      keyPoints: (v.keyPoints as unknown[]).map(String),
    };
  },
};

// â”€â”€ Step functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Step 0 â€” initialise conversation memory and KV store
function initMemoryAndState(s: BriefingState): void {
  conversationMemory.add({
    role: "system",
    content: `You are writing a briefing on: "${s.topic}".`,
  });
  kvMemory.set("topic", s.topic);
  console.log(`  ğŸ§   Memory initialised. Topic stored in KV: "${s.topic}"`);
}

// Step 1 â€” ReAct research phase
// think() is called once per iteration; it reads tool results from the
// previous round (s.__toolResults) and either fires more tool calls or
// signals FINISH.
async function researchThink(s: BriefingState): Promise<ThinkResult> {
  const priorResults = s.__toolResults ?? [];
  const context =
    priorResults.length > 0
      ? "\nPrevious tool results:\n" +
        priorResults
          .map((r) => `  [${r.name}] ${JSON.stringify(r.result)}`)
          .join("\n")
      : "";

  const memContext = conversationMemory.toContext();
  const prompt = `You are researching the topic: "${s.topic}".
${memContext}${context}

Your available tools are: search, calculate, wiki_summary.
If you have enough information to write a briefing, reply with:
  { "action": "finish" }
Otherwise reply with:
  { "action": "tool", "calls": [{ "name": "<tool>", "args": { ... } }] }

Reply with ONLY valid JSON.`;

  const raw = await callLlm(prompt);
  conversationMemory.add({ role: "assistant", content: raw });

  const parsed = parseJsonOutput<{ action: string; calls?: ToolCall[] }>(raw);

  if (parsed.action === "finish" || !parsed.calls?.length) {
    return { action: "finish" };
  }

  return { action: "tool", calls: parsed.calls };
}

// Called after each tool-execution round â€” append observations to memory
async function onToolObservation(
  results: ToolResult[],
  s: BriefingState,
): Promise<void> {
  for (const r of results) {
    const content = `Tool "${r.name}" returned: ${JSON.stringify(r.result ?? r.error)}`;
    conversationMemory.add({ role: "tool", content });
    s.facts.push(content);
  }
  console.log(
    `  ğŸ”  Observation round: ${results.length} tool result(s) recorded`,
  );
}

// Step 2 â€” pull facts gathered by the ReAct loop into structured list
function consolidateFacts(s: BriefingState): void {
  // parseListOutput strips numbering / bullets from a text block
  const rawFacts = s.facts.join("\n");
  const cleaned = parseListOutput(rawFacts);
  s.facts = cleaned.length > 0 ? cleaned : s.facts;
  kvMemory.set("facts", JSON.stringify(s.facts));
  console.log(`  ğŸ“‹  ${s.facts.length} facts consolidated`);
}

// â”€â”€ Inner section graph â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Declare the intro/body/conclusion workflow as a DAG and compile it.
// In a real system this section graph could be shared / reused.

async function draftIntro(s: BriefingState): Promise<void> {
  console.log("    âœï¸  [graph] drafting intro");
  const { text, usage } = await callLlmWithUsage(
    `Write a 2-sentence introduction for a briefing titled "${s.topic}".`,
  );
  s.intro = text.trim();
  s.tokensUsed += usage.totalTokens;
  s.__stepCost = calcCost(usage.inputTokens, usage.outputTokens);
}

async function draftBody(s: BriefingState): Promise<void> {
  console.log("    âœï¸  [graph] drafting body");
  const facts = s.facts.slice(0, 5).join("\n");
  const { text, usage } = await callLlmWithUsage(
    `Write a 3-paragraph body section for a briefing on "${s.topic}".\nFacts:\n${facts}`,
  );
  s.body = text.trim();
  s.tokensUsed += usage.totalTokens;
  s.__stepCost = calcCost(usage.inputTokens, usage.outputTokens);
}

async function draftConclusion(s: BriefingState): Promise<void> {
  console.log("    âœï¸  [graph] drafting conclusion");
  const { text, usage } = await callLlmWithUsage(
    `Write a 1-paragraph conclusion for a briefing on "${s.topic}".`,
  );
  s.conclusion = text.trim();
  s.tokensUsed += usage.totalTokens;
  s.__stepCost = calcCost(usage.inputTokens, usage.outputTokens);
}

// Compile graph: intro â†’ body â†’ conclusion (linear for simplicity;
// addEdge() supports conditional edges and back-edges for complex DAGs)
const sectionGraph = new FlowBuilder<BriefingState>()
  .addNode("intro", draftIntro)
  .addNode("body", draftBody)
  .addNode("conclusion", draftConclusion)
  .addEdge("intro", "body")
  .addEdge("body", "conclusion")
  .compile();

// Step 3 â€” run the compiled section graph as a sub-flow
async function runSectionGraph(s: BriefingState): Promise<void> {
  console.log("  ğŸ“  Running compiled section graph â€¦");
  await sectionGraph.run(s);
}

// parallelAtomic fns for quality-check pass (same pattern as v1)
async function checkIntroQuality(s: BriefingState): Promise<void> {
  const { text, usage } = await callLlmWithUsage(
    `Rate this intro from 0.0â€“1.0 (number only):\n${s.intro}`,
  );
  const score = parseFloat(text);
  console.log(
    `    â¬¡  [parallel] intro quality: ${isNaN(score) ? "?" : score.toFixed(2)}`,
  );
  s.tokensUsed += usage.totalTokens;
  s.__stepCost = calcCost(usage.inputTokens, usage.outputTokens);
}

async function checkBodyQuality(s: BriefingState): Promise<void> {
  const { text, usage } = await callLlmWithUsage(
    `Rate this body from 0.0â€“1.0 (number only):\n${s.body}`,
  );
  const score = parseFloat(text);
  console.log(
    `    â¬¡  [parallel] body quality:  ${isNaN(score) ? "?" : score.toFixed(2)}`,
  );
  s.tokensUsed += usage.totalTokens;
  s.__stepCost = calcCost(usage.inputTokens, usage.outputTokens);
}

async function checkConclusionQuality(s: BriefingState): Promise<void> {
  const { text, usage } = await callLlmWithUsage(
    `Rate this conclusion from 0.0â€“1.0 (number only):\n${s.conclusion}`,
  );
  const score = parseFloat(text);
  console.log(
    `    â¬¡  [parallel] conclusion quality: ${isNaN(score) ? "?" : score.toFixed(2)}`,
  );
  s.tokensUsed += usage.totalTokens;
  s.__stepCost = calcCost(usage.inputTokens, usage.outputTokens);
}

// Step 4 â€” synthesise into structured JSON and write to __llmOutput
// (withStructuredOutput will validate it and write to __structuredOutput)
async function synthesizeBriefing(s: BriefingState): Promise<void> {
  console.log("  âœï¸  Synthesising structured briefing â€¦");
  const { text, usage } = await callLlmWithUsage(
    `You are finalising a briefing on "${s.topic}".

Sections:
INTRO: ${s.intro}
BODY:  ${s.body}
CONCLUSION: ${s.conclusion}

Reply ONLY with a JSON object matching this schema:
{ "title": string, "summary": string (1-2 sentences), "keyPoints": string[] (3-5 items) }`,
  );
  s.__llmOutput = text.trim(); // withStructuredOutput reads this key
  s.tokensUsed += usage.totalTokens;
  s.__stepCost = calcCost(usage.inputTokens, usage.outputTokens);
}

// Promote validated structured output into named field
function promoteStructuredOutput(s: BriefingState): void {
  if (s.__structuredOutput) {
    s.briefing = s.__structuredOutput as BriefingState["briefing"];
    console.log(`  âœ…  Structured briefing validated: "${s.briefing?.title}"`);
  } else if (s.__validationError) {
    console.warn(
      `  âš   Structured output validation failed: ${s.__validationError}`,
    );
  }
}

// Step 8 â€” parseRegexOutput demo: extract a score pattern from a key point
// (real-world use: pull version numbers, dates, percentages from LLM text)
function parseKeyPointsDemo(s: BriefingState): void {
  if (!s.briefing?.keyPoints.length) return;
  // Try to extract a "N%" or "N/M" pattern from the first key point
  const first = s.briefing.keyPoints[0] ?? "";
  const match = parseRegexOutput(
    first,
    /(?<numerator>\d+)\s*[%\/]\s*(?<denominator>\d+)?/,
  );
  if (match) {
    console.log(
      `  ğŸ”  Regex match in first key point: ${JSON.stringify(match)}`,
    );
  } else {
    console.log(`  ğŸ”  No numeric pattern found in: "${first.slice(0, 60)}"`);
  }
}

// Eval flow â€” a tiny FlowBuilder used as the "system under test" by runEvalSuite.
// It simply copies `shared.output` through, letting scoreFns read the final state.
interface EvalItem {
  topic: string;
  output: string;
  keyPoints: string[];
}

const evalFlow = new FlowBuilder<EvalItem>().startWith((_s) => {
  // No-op: the flow just runs once so scoreFns can inspect the final state.
});

// Step 6 â€” run eval suite against the final briefing (post-flow quality gate)
async function runEvaluation(s: BriefingState): Promise<void> {
  if (!s.briefing) return;
  console.log("  ğŸ“Š  Running eval suite â€¦");

  const keyword = s.topic.split(" ")[0] ?? "quantum";

  // Build a one-item dataset from the finished briefing
  const dataset: EvalItem[] = [
    {
      topic: s.topic,
      output: s.briefing.summary,
      keyPoints: s.briefing.keyPoints,
    },
  ];

  const { results, summary } = await runEvalSuite<EvalItem>(dataset, evalFlow, {
    // Each ScoreFn<EvalItem> receives the final EvalItem shared state
    containsTopic: (item: EvalItem) => containsMatch(item.output, keyword),
    f1Quality: (item: EvalItem) => f1Score(item.output, item.topic),
    relevance: (item: EvalItem) =>
      answerRelevance(item.output, item.topic.split(" ").slice(0, 3)),
  });

  s.evalResults = results as unknown as EvalResult<BriefingState>[];
  console.log(
    `  ğŸ“ˆ  Eval complete â€” avg scores: ${Object.entries(summary.averages)
      .map(([k, v]) => `${k}=${v.toFixed(2)}`)
      .join(" | ")}`,
  );
}

// Step 7 â€” publish via channel + stream
function publishBriefing(s: BriefingState): void {
  sendTo(s, "briefings", s.briefing);
  const published = receiveFrom<BriefingState["briefing"]>(s, "briefings");
  const b = published[0];
  if (!b) return;

  emit(s, { type: "briefing", title: b.title, summary: b.summary });

  console.log("\n" + "â•".repeat(70));
  console.log(`ğŸ“°  FINAL BRIEFING â€” "${b.title}"`);
  console.log("â•".repeat(70));
  console.log(`SUMMARY: ${b.summary}`);
  console.log("\nKEY POINTS:");
  b.keyPoints.forEach((kp, i) => console.log(`  ${i + 1}. ${kp}`));
  console.log("â•".repeat(70) + "\n");
}

// Fallback handler
function gracefulFallback(s: BriefingState): void {
  const fe = s.__fallbackError;
  s.lastError = fe
    ? `Step ${fe.stepIndex} (${fe.stepType}) failed: ${fe.message}`
    : "A step failed â€” flow degraded gracefully.";
  console.error("  âš   Fallback triggered:", s.lastError);
}

// â”€â”€ Budget â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const TOKEN_BUDGET = 60_000;

// â”€â”€ Main flow definition â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const flow = new FlowBuilder<BriefingState>()

  // â”€â”€ Resilience â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  .withCircuitBreaker({
    maxFailures: 3,
    resetMs: 15_000,
  } satisfies CircuitBreakerOptions)
  .withTimeout(90_000) // 90s wall-clock cap per step
  .withCycles(50) // max anchor-jumps
  .withStepLimit(300) // max step executions

  // â”€â”€ Persistence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // NEW: diff-based versioned checkpoints (git-like branching)
  .withVersionedCheckpoint(versionedStore)
  .withAuditLog(auditStore)

  // â”€â”€ LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  .withTokenBudget(TOKEN_BUDGET)
  .withCostTracker()
  .withRateLimit({ intervalMs: 200 })
  // NEW: validate structured synthesis output via briefingSchema
  .withStructuredOutput(briefingSchema, {
    outputKey: "__llmOutput",
    retries: 2,
  })

  // â”€â”€ Observability â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  .withHistory()
  .withTiming()
  // NEW: label-aware lifecycle callbacks (fires on llm:* / tool:* / agent:* labels)
  .withCallbacks(callbacks)
  // NEW: OTEL-style spans via shared TelemetryDaemon
  .withTelemetry({ daemon: telemetryDaemon })

  // â”€â”€ Messaging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  .withChannels()
  .withStream((chunk) => {
    const c = chunk as { type: string; title?: string; summary?: string };
    if (c.type === "briefing") {
      console.log(
        `  ğŸ“¡  [stream] briefing: "${c.title}" â€” ${String(c.summary).slice(0, 60)}â€¦`,
      );
    }
  })

  // â”€â”€ Memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // NEW: attach BufferWindowMemory â€” available as shared.__memory in steps
  .withMemory(conversationMemory)

  // â”€â”€ Tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // NEW: register ToolRegistry â€” shared.__tools used by withReActLoop
  .withTools([searchTool, calculatorTool, wikiFetchTool])

  // â”€â”€ Error recovery â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  .withFallback(gracefulFallback)

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Steps
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  // Step 0 â€” init memory
  .startWith(initMemoryAndState)

  // Step 1 â€” ReAct research loop (agent:* label fires onAgentAction/Finish)
  // NEW: .withReActLoop() replaces manual while-loops like clawneer.ts
  .withReActLoop({
    think: researchThink,
    maxIterations: 4,
    onObservation: onToolObservation,
  })

  // Step 2 â€” consolidate facts gathered by the agent
  .then(consolidateFacts)

  // Step 3 â€” human gate: only fires if no facts were gathered
  //   - NEW: .humanNode() replaces raw .interruptIf() + manual savedShared handling
  //   - resumeFlow() is called by the catch block below when human provides feedback
  .humanNode({
    condition: (s) => s.facts.length === 0,
    prompt: "No facts gathered. Please provide seed context for the briefing:",
  })

  // Step 4 â€” run compiled section graph (intro â†’ body â†’ conclusion)
  .then(runSectionGraph)

  // Step 5 â€” parallel quality check; each fn gets an isolated draft copy
  .parallelAtomic(
    [checkIntroQuality, checkBodyQuality, checkConclusionQuality],
    (_shared, _drafts) => {
      // quality scores are logged inline; no merge needed here
    },
  )

  // Step 6 â€” synthesise structured briefing; withStructuredOutput validates
  //   shared.__llmOutput and writes result to shared.__structuredOutput
  .then(synthesizeBriefing, { retries: 2, delaySec: 1 })

  // Step 7 â€” promote __structuredOutput â†’ s.briefing
  .then(promoteStructuredOutput)

  // Step 8 â€” regex parser demo (named entity extraction from key points)
  .then(parseKeyPointsDemo)

  // Step 9 â€” eval suite
  .then(runEvaluation)

  // Step 10 â€” publish via channels + stream
  .then(publishBriefing);

// â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function main() {
  const shared: BriefingState = {
    topic: "large-scale quantum error correction breakthroughs 2025",
    facts: [],
    tokensUsed: 0,
  };

  const ac = new AbortController();
  const abortTimer = setTimeout(() => ac.abort(), 8 * 60 * 1_000); // 8 min

  console.log(
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
  );
  console.log(
    "â”‚  Flowneer â€” Kitchen-Sink v2: Multi-Agent Tech Briefing System   â”‚",
  );
  console.log(
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
  );

  try {
    await flow.run(shared, {}, { signal: ac.signal });
  } catch (e) {
    if (e instanceof InterruptError) {
      // â”€â”€ humanNode paused because facts were empty â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      // In a real app: persist e.savedShared, send __humanPrompt to the user,
      // wait for input, then call resumeFlow() to restart from the saved step.
      console.warn("\nâ¸  Flow paused at humanNode.");
      console.log(
        `   Prompt: ${(e.savedShared as BriefingState).__humanPrompt}`,
      );
      console.log("   Demo: providing mock human feedback and resuming â€¦\n");

      // Inject human feedback into the saved snapshot
      const restored = e.savedShared as BriefingState;
      restored.__humanFeedback =
        "Focus on IBM and Google quantum milestones from 2025.";
      restored.facts = [`Human context: ${restored.__humanFeedback}`];

      // resumeFlow() skips already-completed steps and continues from the
      // interrupt point. The step index is carried in e.stepIndex.
      await resumeFlow(flow, restored, {}, (e as any).stepIndex ?? 3);
    } else if (e instanceof FlowError) {
      console.error(`\nâœ–  FlowError at step "${e.step}":`, e.cause);
    } else {
      throw e;
    }
  } finally {
    clearTimeout(abortTimer);
    // Flush any remaining telemetry spans
    await telemetryDaemon.stop();
  }

  // â”€â”€ Post-run diagnostics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  console.log(
    "â”€â”€â”€ Run diagnostics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€",
  );
  console.log(
    `  Tokens used  : ${shared.tokensUsed.toLocaleString()} / ${TOKEN_BUDGET.toLocaleString()}`,
  );
  console.log(`  Total cost   : $${(shared.__cost ?? 0).toFixed(6)}`);
  console.log(`  Facts gathered : ${shared.facts.length}`);
  console.log(`  Audit entries  : ${auditLog.length}`);
  console.log(`  Agent exhausted: ${shared.__reactExhausted ?? false}`);

  if (shared.__timings) {
    const totalTime = Object.values(shared.__timings).reduce(
      (s, ms) => s + ms,
      0,
    );
    console.log(`  Total time   : ${totalTime}ms`);
  }

  if (shared.__history) {
    console.log(`  History snapshots: ${shared.__history.length}`);
  }

  if (shared.evalResults?.length) {
    console.log(`  Eval results : ${shared.evalResults.length} entries`);
  }

  // Show KV memory entries
  console.log(
    `  KV fact store: topic="${kvMemory.getValue("topic")}", facts=${kvMemory.getValue("facts") !== undefined ? "stored" : "missing"}`,
  );

  if (shared.lastError) {
    console.warn(`  âš   Degraded run â€” fallback fired: ${shared.lastError}`);
  }
}

main().catch(console.error);

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// APPENDIX A: Resuming with withVersionedCheckpoint (git-like branching)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// withVersionedCheckpoint saves a diff after each step (only changed keys).
// To resume from an earlier point and run a different "branch":
//
//   await new FlowBuilder<BriefingState>()
//     .withVersionedCheckpoint(versionedStore)
//     // â€¦ all same plugins â€¦
//     .resumeFrom("v3", versionedStore) // resolves snapshot at step 3
//     .startWith(initMemoryAndState)
//     // â€¦ same steps â€¦
//     .run(newShared);
//
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// APPENDIX B: supervisorCrew / sequentialCrew (multi-agent patterns)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Instead of manually wiring parallel steps, use factory helpers:
//
//   import { supervisorCrew, sequentialCrew } from "flowneer/plugins/agent";
//
//   // Supervisor assigns tasks; workers draft subsections in parallel
//   const crew = supervisorCrew<BriefingState>(
//     async (s) => { s.tasks = splitTopics(s.topic); },
//     [
//       async (s) => { s.intro = await draftSection("intro", s); },
//       async (s) => { s.body  = await draftSection("body",  s); },
//     ],
//     { post: async (s) => { s.briefing = merge(s); } },
//   );
//   await crew.run(shared);
//
//   // Linear pipeline â€” pass each step as an array
//   const pipeline = sequentialCrew<BriefingState>([
//     fetchData, analyzeData, formatData,
//   ]);
//   await pipeline.run(shared);
//
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// APPENDIX C: withGraph â€” declare a sub-pipeline as a DAG
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// The `sectionGraph` above is compiled from addNode/addEdge calls.
// For conditional routing add a predicate to addEdge():
//
//   .addEdge("body", "expandBody", (s) => s.qualityScore < 0.7)
//   .addEdge("body", "conclusion",  (s) => s.qualityScore >= 0.7)
//
// This compiles to a .branch() call in the underlying FlowBuilder chain.
//
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// APPENDIX D: runEvalSuite â€” offline quality assurance
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Run a dataset against any scoring functions offline without modifying the
// main flow. Useful for CI:
//
//   import { runEvalSuite, f1Score, exactMatch } from "flowneer/plugins/eval";
//
//   const dataset = [
//     { input: "What is quantum computing?", expected: "quantum" },
//     { input: "Explain GPT-4 in one sentence.", expected: "language model" },
//   ];
//
//   const summary = await runEvalSuite(
//     dataset,
//     async (entry) => callLlm(entry.input),
//     { f1: f1Score, exact: exactMatch },
//   );
//   console.log(summary.averageScores); // { f1: 0.73, exact: 0.5 }
